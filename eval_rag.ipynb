{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of RAG respones to 'Where', 'When' and 'Who' questions\n",
    "\n",
    "Evalation with the help of the helpers.rag_evaluate methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from helpers.rag_evaluate import evaluate_category, evaluate_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samue\\anaconda3\\envs\\wa-event-data\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pipelines.rag import RAGPipeline\n",
    "\n",
    "index_name = \"football_index_711\" #TODO: set the index name\n",
    "\n",
    "# Initialize the pipeline\n",
    "rag = RAGPipeline(openai_embedding_model=\"text-embedding-3-small\")\n",
    "\n",
    "# load the FAISS index\n",
    "rag.load_faiss_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(data, question_column, response_column, rag, kwargs = {\"retrieve\": 200, \"top_k\": 250, \"reorder\": True}\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates responses for questions in a specified column of a DataFrame\n",
    "    using a RAG pipeline and populates the responses in another specified column.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): DataFrame containing the questions.\n",
    "    - question_column (str): Name of the column containing the questions.\n",
    "    - response_column (str): Name of the column where responses will be stored.\n",
    "    - rag (object): An instance of the RAG pipeline with an 'answer_query' method.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Updated DataFrame with answers in the specified response column.\n",
    "    \"\"\"\n",
    "    for i, row in data.iterrows():\n",
    "        # Get the question\n",
    "        question = row[question_column]\n",
    "\n",
    "        # Answer the question using the RAG pipeline\n",
    "        answer, _, _, _, _ = rag.answer_query(question)\n",
    "\n",
    "        # Assign the answer to the specified response column\n",
    "        data.loc[i, response_column] = answer\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the questions file - queries and ground truth answers\n",
    "save_path = \"data/results\"\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Eval of 'When?' Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load in the when data\n",
    "when_data = pd.read_json(os.path.join(save_path, 'when.json'))\n",
    "\n",
    "regenerate_responses = False # TODO: set to True if you want to regenerate responses\n",
    "\n",
    "if regenerate_responses:\n",
    "    updated_data = generate_responses(data=when_data, \n",
    "                            question_column='question', \n",
    "                            response_column='response', \n",
    "                            rag=rag)\n",
    "else:\n",
    "    if 'response' not in when_data.columns:\n",
    "        Raise(\"Response column not found in the data. Set regenerate_responses=True to generate responses.\")\n",
    "\n",
    "when_metrics, when_results = evaluate_category(when_data, 'ground_truth')\n",
    "\n",
    "when_data['eval'] = when_results\n",
    "when_data.to_json(os.path.join(save_path, 'when.json'), orient='records', indent=4)\n",
    "\n",
    "# Print the results\n",
    "print(\"When Metrics:\")\n",
    "print(json.dumps(when_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Eval of 'Where?' Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.7\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load in the where data\n",
    "where_data = pd.read_json(os.path.join(save_path, 'where.json'))\n",
    "\n",
    "regenerate_responses = False # TODO: set to True if you want to regenerate responses\n",
    "\n",
    "if regenerate_responses:\n",
    "    updated_data = generate_responses(data=where_data, \n",
    "                            question_column='question', \n",
    "                            response_column='response', \n",
    "                            rag=rag)\n",
    "else:\n",
    "    if 'response' not in where_data.columns:\n",
    "        Raise(\"Response column not found in the data. Set regenerate_responses=True to generate responses.\")\n",
    "\n",
    "where_metrics, where_results = evaluate_category(where_data, 'ground_truth')\n",
    "\n",
    "where_data['eval'] = where_results\n",
    "where_data.to_json(os.path.join(save_path, 'where.json'), orient='records', indent=4)\n",
    "\n",
    "# Print the results\n",
    "print(\"Where Metrics:\")\n",
    "print(json.dumps(where_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Eval of 'Who?' Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load in the who data\n",
    "who_data = pd.read_json(os.path.join(save_path, 'who.json'))\n",
    "\n",
    "regenerate_responses = False # TODO: set to True if you want to regenerate responses\n",
    "\n",
    "if regenerate_responses:\n",
    "    updated_data = generate_responses(data=who_data, \n",
    "                            question_column='question', \n",
    "                            response_column='response', \n",
    "                            rag=rag)\n",
    "else:\n",
    "    if 'response' not in who_data.columns:\n",
    "        Raise(\"Response column not found in the data. Set regenerate_responses=True to generate responses.\")\n",
    "\n",
    "who_metrics, who_results = evaluate_category(who_data, 'ground_truth')\n",
    "\n",
    "who_data['eval'] = who_results\n",
    "who_data.to_json(os.path.join(save_path, 'who.json'), orient='records', indent=4)\n",
    "\n",
    "# Print the results\n",
    "print(\"Who Metrics:\")\n",
    "print(json.dumps(who_metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Eval across categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "{\n",
      "    \"accuracy\": 0.6333333333333333\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data = [when_data, where_data, who_data]\n",
    "metrics = evaluate_all_data(data)\n",
    "\n",
    "# Print the results\n",
    "\n",
    "print(\"Metrics:\")\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wa-event-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
